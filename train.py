import argparseimport numpy as npimport torchimport torch.optim as optimimport torch.nn as nnimport torch.nn.functional as Fimport torchvisionimport matplotlib.pyplot as pltfrom model_fc import Generator, Discriminatorfrom model_dc import Generator_DC, Discriminator_DCfrom loss import loss_G, loss_Dfrom data import train_loader# argparse -----------------------------------------------------parser = argparse.ArgumentParser(description='Model and Parameters for GAN Training')parser.add_argument('--model', type=str, default='DC', help='wheter model you use')parser.add_argument('--epoch', type=int, default='100')parser.add_argument('--batch_size', type=int, default='32')parser.add_argument('--train_g', type=int, default='1')parser.add_argument('--train_d', type=int, default='1')args = parser.parse_args()# cuda ---------------------------------------------------------device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')# nan error check ----------------------------------------------def nan_inf_error(input_, N):    # loss check    flag = False    if torch.isnan(input_) == 1:        flag = True        print('-----{} loss is nan-----'.format(N))    elif torch.max(input_).item() == float('Inf'):        flag = True        print('-----{} loss is if-----'.format(N))    if flag:        print('i: ', i)        print('z: ', z)        if N == 'D':            print('output_r: ', output_r)        print('output_f: ', output_f)        print('loss: ', loss)    return flag# train ---------------------------------------------------------batch_size = args.batch_sizeepochs = args.epochtrain_loader = train_loader(args.batch_size)cycle = torch.floor(torch.FloatTensor([len(train_loader)], device=device) / 10).item()if args.model == 'DC':    G = Generator_DC()    D = Discriminator_DC()else:    G = Generator()    D = Discriminator()G.to(device)D.to(device)optimizer_G = optim.Adam(G.parameters(), lr=1e-3)optimizer_D = optim.SGD(D.parameters(), lr=1e-3, momentum=0.9)flag = Falsefor epoch in range(epochs):    running_loss_G = 0.0    running_loss_D = 0.0    for i, data in enumerate(train_loader, 0):        # noise        if args.model == 'DC':            z = torch.randn(batch_size, 100, device=device).view(-1, 100, 1, 1)        else:            z = torch.rand(batch_size, 1, device=device)        # opt D        D_loss = 0        for j in range(args.train_d):            optimizer_D.zero_grad()            # real            real = data[0].view(-1, 1, 28, 28)            real = real.to(device)            output_r = D(real)            # fake            fake = G(z)            output_f = D(fake)            loss = loss_D(output_r, output_f, batch_size)            # loss check            flag = nan_inf_error(loss, 'D')            if flag:                break            loss.backward()            optimizer_D.step()            D_loss += loss.item()        if flag:            break        G_loss = 0        for j in range(args.train_g):            # opt G            optimizer_G.zero_grad()            fake = G(z)            output_f = D(fake)            loss = loss_G(output_f, batch_size)            # loss check            flag = nan_inf_error(loss, 'G')            if flag:                break            loss.backward()            optimizer_G.step()            G_loss += loss.item()        if flag:            break        running_loss_G += G_loss        running_loss_D += D_loss        if i % cycle == 0:            print('[%d, %6d] loss_G: %f loss_D: %f' %                    (epoch, i, running_loss_G / cycle, running_loss_D / cycle))            running_loss_G = 0.0            running_loss_D = 0.0    if flag:        break    # model save    torch.save(G.state_dict(), './model_save/G.pth')    torch.save(D.state_dict(), './model_save/D.pth')    # if epoch % (epochs / 10) == 0:    #print("---------------GENERATOR TEST-----------------")    #if args.model == 'DC':    #    test_z = torch.randn(batch_size, 100, requires_grad=False, device=device).view(-1, 100, 1, 1)    #else:    #    test_z = torch.rand(batch_size, 1, requires_grad=False, device=device)    #test_img = G(test_z)    #test_img = test_img.view(-1, 28, 28)    #for k in range(4):        # grid = torchvision.utils.make_grid(test_img)        # torchvision.utils.save_image(grid, './gen_img/{}_{}_gan.png'.format(epoch, k))        # plt.imshow(test_img[k].data)        # plt.gray()        # plt.savefig('./gen_img/{}_{}_gan.png'.format(epoch, k))print('Finished Training!')