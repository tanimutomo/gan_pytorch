import argparseimport numpy as npimport torchimport torch.optim as optimimport torch.nn as nnimport torch.nn.functional as Fimport torchvisionfrom torchvision.utils import save_imageimport matplotlib.pyplot as pltfrom model.mlp import Generator, Discriminatorfrom model.cnn import Generator_CNN, Discriminator_CNNfrom utils.loss_gan import loss_G, loss_Dfrom utils.loss_wgan import loss_wG, loss_wDfrom utils.data import train_loader# argparse -----------------------------------------------------parser = argparse.ArgumentParser(description='Model and Parameters for GAN Training')parser.add_argument('--model', type=str, default='CNN', help='wheter model you use')parser.add_argument('--loss', type=str, default='gan', help='wheter loss you use')parser.add_argument('--lr', type=float, default=1e-5)parser.add_argument('--clip_value', type=float, default=1e-2)parser.add_argument('--not_sig', action='store_false')parser.add_argument('--epoch', type=int, default=100)parser.add_argument('--batch_size', type=int, default=32)parser.add_argument('--train_g', type=int, default=1)parser.add_argument('--train_d', type=int, default=1, help='set 5, if you use wgan loss')parser.add_argument('--g_start_epoch', type=int, default=0)parser.add_argument('--cuda', type=int, default=0)args = parser.parse_args()# cuda ---------------------------------------------------------device = torch.device('cuda:{}'.format(args.cuda) if torch.cuda.is_available() else 'cpu')# clip_grad_value ----------------------------------------------def clip_grad_value_(parameters, clip_value):    clip_value = float(clip_value)    for p in parameters:        p.grad.data.clamp_(min=-clip_value, max=clip_value)# nan error check ----------------------------------------------def nan_inf_error(input_, N):    # loss check    flag = False    if torch.isnan(input_) == 1:        flag = True        print('-----{} loss is nan-----'.format(N))    elif torch.max(input_).item() == float('Inf'):        flag = True        print('-----{} loss is if-----'.format(N))    if flag:        print('i: ', i)        print('z: ', z)        if N == 'D':            print('output_r: ', output_r)        print('output_f: ', output_f)        print('loss: ', loss)    return flag# train ---------------------------------------------------------batch_size = args.batch_sizeepochs = args.epochtrain_loader = train_loader(args.batch_size)cycle = torch.floor(torch.FloatTensor([len(train_loader)], device=device) / 10).item()if args.model == 'CNN':    G = Generator_CNN()    D = Discriminator_CNN()else:    G = Generator()    D = Discriminator()G.to(device)D.to(device)if args.loss == 'gan':    optimizer_G = optim.Adam(G.parameters(), lr=args.lr)    optimizer_D = optim.SGD(D.parameters(), lr=args.lr, momentum=0.9)if args.loss == 'wgan':    optimizer_G = optim.RMSprop(G.parameters(), lr=args.lr)    optimizer_D = optim.RMSprop(D.parameters(), lr=args.lr)flag = Falsefor epoch in range(epochs):    mean_loss_G = 0.0    mean_loss_D = 0.0    for i, data in enumerate(train_loader, 0):        # noise        if args.model == 'CNN':            z = torch.randn(batch_size, 100, device=device).view(-1, 100, 1, 1)        else:            z = torch.rand(batch_size, 1, device=device)        # opt D        Tloss_D = 0        for j in range(args.train_d):            optimizer_D.zero_grad()            # real            real = data[0].view(-1, 1, 28, 28)            real = real.to(device)            output_r = D(real, use_sig=args.not_sig)            # fake            fake = G(z)            output_f = D(fake, use_sig=args.not_sig)            if args.loss == 'gan':                loss_D = loss_D(output_r, output_f, batch_size)            elif args.loss == 'wgan':                loss_D = loss_wD(output_r, output_f)            # loss check            flag = nan_inf_error(loss_D, 'D')            if flag:                break            loss_D.backward()            optimizer_D.step()            clip_grad_value_(D.parameters(), args.clip_value)            Tloss_D += loss_D.item()        if flag:            break        Tloss_G = 0        if epoch >= args.g_start_epoch:            for j in range(args.train_g):                # opt G                optimizer_G.zero_grad()                fake = G(z)                output_f = D(fake)                if args.loss == 'gan':                    loss_G = loss_G(output_f, batch_size)                elif args.loss == 'wgan':                    loss_G = loss_wG(output_f)                # loss check                flag = nan_inf_error(loss_G, 'G')                if flag:                    break                loss_G.backward()                optimizer_G.step()                Tloss_G += loss_G.item()        if flag:            break        mean_loss_G += Tloss_G        mean_loss_D += Tloss_D        if i % cycle == 0:            print('[%d, %6d] loss_G: %f loss_D: %f' %                    (epoch, i, mean_loss_G / (cycle * batch_size), mean_loss_D / (cycle * batch_size)))            mean_loss_G = 0.0            mean_loss_D = 0.0    if flag:        break    # save image    if args.model == 'CNN':        z = torch.randn(batch_size, 100, device=device).view(-1, 100, 1, 1)    else:        z = torch.rand(batch_size, 1, device=device)        gen_imgs = G(z)    save_image(gen_imgs.data[:25], 'images/%d.png' % epoch, nrow=5, normalize=True)    # model save    torch.save(G.state_dict(), './weights/G.pth')    torch.save(D.state_dict(), './weights/D.pth')